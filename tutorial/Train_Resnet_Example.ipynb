{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6Y7pqdCpjmZjA1zNg4FC7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Training classification using Resnet with custom dataset**\n","* **---------Gender Classification Example---------------------**"],"metadata":{"id":"RE84pT05HPBS"}},{"cell_type":"markdown","source":["**1. Clone repository**"],"metadata":{"id":"DTQTU3ZLHmeS"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4rOWKLIGBjAj","executionInfo":{"status":"ok","timestamp":1696345354865,"user_tz":-420,"elapsed":767,"user":{"displayName":"ANH Lương","userId":"00083566942636669959"}},"outputId":"6abc07d9-2796-4abb-e5f1-2521cf449a04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Resnet_AnhLT'...\n","remote: Enumerating objects: 52, done.\u001b[K\n","remote: Counting objects: 100% (52/52), done.\u001b[K\n","remote: Compressing objects: 100% (44/44), done.\u001b[K\n","remote: Total 52 (delta 18), reused 34 (delta 7), pack-reused 0\u001b[K\n","Receiving objects: 100% (52/52), 38.15 KiB | 5.45 MiB/s, done.\n","Resolving deltas: 100% (18/18), done.\n"]}],"source":["!git clone https://github.com/LuongTuanAnh163002/Resnet_AnhLT.git"]},{"cell_type":"markdown","source":["**2. Install opendatasets packages**"],"metadata":{"id":"e3ifscziHtBy"}},{"cell_type":"code","source":["!pip install opendatasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k1cajebGB3HN","executionInfo":{"status":"ok","timestamp":1696345366284,"user_tz":-420,"elapsed":4277,"user":{"displayName":"ANH Lương","userId":"00083566942636669959"}},"outputId":"c87d5d41-ff1b-4248-aa39-fa0e73cd680c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opendatasets\n","  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n","Installing collected packages: opendatasets\n","Successfully installed opendatasets-0.1.22\n"]}]},{"cell_type":"markdown","source":["**3.Dowload dataset**\n","\n","+ Follow link to take username and key to dowload dataset from your Kaggle acount: https://christianjmills.com/posts/kaggle-obtain-api-key-tutorial/"],"metadata":{"id":"gEiM6J1AHzJ4"}},{"cell_type":"code","source":["import opendatasets as od\n","od.download('https://www.kaggle.com/datasets/gpiosenka/gender-classification-from-an-image?fbclid=IwAR3v_QPJ1jIx7uzoGsagJSkqEThchS166TwwHA5W3e-_cB24nLvVdLRNQKw')"],"metadata":{"id":"R2fUDSBdCozC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**4. Mode to folder Resnet_AnhLT**"],"metadata":{"id":"cocNgOiTH4P4"}},{"cell_type":"code","source":["%cd Resnet_AnhLT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrkWQy37Dx2T","executionInfo":{"status":"ok","timestamp":1696345525357,"user_tz":-420,"elapsed":398,"user":{"displayName":"ANH Lương","userId":"00083566942636669959"}},"outputId":"635e6e9c-0740-47ef-9dba-761541db9a0f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Resnet_AnhLT\n"]}]},{"cell_type":"markdown","source":["**5.Create .yaml file**"],"metadata":{"id":"nAMD_lyxIAxB"}},{"cell_type":"code","source":["!echo 'train: /content/gender-classification-from-an-image/gender/train' >> /content/Resnet_AnhLT/data/gender.yaml\n","!echo 'val: /content/gender-classification-from-an-image/gender/valid' >> /content/Resnet_AnhLT/data/gender.yaml\n","!echo 'nc: 2' >> /content/Resnet_AnhLT/data/gender.yaml\n","!echo \"names: ['female', 'male']\" >> /content/Resnet_AnhLT/data/gender.yaml"],"metadata":{"id":"Cppy20s_CsI_","executionInfo":{"status":"ok","timestamp":1696345529477,"user_tz":-420,"elapsed":572,"user":{"displayName":"ANH Lương","userId":"00083566942636669959"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["**6.Train model**"],"metadata":{"id":"M9AROCp7IFZg"}},{"cell_type":"code","source":["!python train.py --model_type resnet18 --pretrained --freeze --data data/gender.yaml --epochs 1 --device 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uVzx60CTEvR7","executionInfo":{"status":"ok","timestamp":1696345681953,"user_tz":-420,"elapsed":33798,"user":{"displayName":"ANH Lương","userId":"00083566942636669959"}},"outputId":"ca567bef-7ae0-493c-93ee-4fd355808a59"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-03 15:07:33.146965: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-10-03 15:07:34.103182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Start with 'tensorboard --logdir runs/train/exp', view at http://localhost:6006/\n","Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n","100% 44.7M/44.7M [00:00<00:00, 188MB/s]\n","File not found, dowloading from: https://download.pytorch.org/models/resnet18-5c106cde.pth\n","Initilize weight for resnet18 using tranfer learning\n","Freeze for transfer learning\n","Logging results to runs/train/exp\n","Starting training for 1 epochs...\n","\n","          Epoch        gpu_mem     train_loss       accuracy\n","            0/0         0.143G        0.04122         0.6554: 100% 219/219 [00:12<00:00, 18.22it/s]\n","            Val_loss    accuracy: 100% 13/13 [00:00<00:00, 56.70it/s]\n","\n","               0.041       0.725\n","1 epochs completed in 0.003 hours.\n","\n","Precision score: 0.8\n","Recall score: 0.8\n","F1 score: 0.8000000000000002\n","Optimizer stripped from  runs/train/exp/weights/best.pth\n","Optimizer stripped from  runs/train/exp/weights/last.pth\n"]}]},{"cell_type":"markdown","source":["**7.Predict one image**"],"metadata":{"id":"w0eDaEa6IZTC"}},{"cell_type":"code","source":["!python detect.py --source /content/gender-classification-from-an-image/gender/test/female/001.jpg --weights /content/Resnet_AnhLT/runs/train/exp/weights/best.pth --device 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sAZj8U-PFegj","executionInfo":{"status":"ok","timestamp":1696345892015,"user_tz":-420,"elapsed":8083,"user":{"displayName":"ANH Lương","userId":"00083566942636669959"}},"outputId":"a28c6c97-6fb9-493f-fa97-4713bc45d8cd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting for one image\n","Results saved to runs/detect/exp\n","Done. (2.331s)\n"]}]}]}